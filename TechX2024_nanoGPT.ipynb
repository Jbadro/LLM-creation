{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOBY8W3L4ez3A28DYrGAkHf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jbadro/LLM-creation/blob/main/TechX2024_nanoGPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "PBYqmPgdlG-6",
        "outputId": "0f47be58-0d11-4668-d4fb-390f4e1041ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-16 15:24:21--  http://gir.fyi/techx/input.txt\n",
            "Resolving gir.fyi (gir.fyi)... 216.239.38.21, 216.239.36.21, 216.239.32.21, ...\n",
            "Connecting to gir.fyi (gir.fyi)|216.239.38.21|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt [following]\n",
            "--2024-05-16 15:24:21--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2024-05-16 15:24:22 (19.2 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://gir.fyi/techx/input.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "  raw_training_data = f.read()\n",
        "\n",
        "print(len(raw_training_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpzoRUSootVZ",
        "outputId": "ce1f5df9-291f-4ddf-9931-722876727160"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1115394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(set(raw_training_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3p_-nu9cpBwa",
        "outputId": "cf57df22-2461-48f4-8d8a-433c956a4e11"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''.join(sorted(set(raw_training_data)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-h1H7MVUparm",
        "outputId": "478fd443-fb4d-4155-82cc-f46fdc5eb52d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "freqs = defaultdict(int)\n",
        "\n",
        "for letter in raw_training_data:\n",
        "  freqs[letter] += 1\n",
        "\n",
        "freqs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zAaYON_Bp_lf",
        "outputId": "496296e9-f006-49a6-aff9-0865dd4932c0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(int,\n",
              "            {'F': 1797,\n",
              "             'i': 45537,\n",
              "             'r': 48889,\n",
              "             's': 49696,\n",
              "             't': 67009,\n",
              "             ' ': 169892,\n",
              "             'C': 3820,\n",
              "             'z': 356,\n",
              "             'e': 94611,\n",
              "             'n': 48529,\n",
              "             ':': 10316,\n",
              "             '\\n': 40000,\n",
              "             'B': 2761,\n",
              "             'f': 15770,\n",
              "             'o': 65798,\n",
              "             'w': 17585,\n",
              "             'p': 10808,\n",
              "             'c': 15623,\n",
              "             'd': 31358,\n",
              "             'a': 55507,\n",
              "             'y': 20448,\n",
              "             'u': 26584,\n",
              "             'h': 51310,\n",
              "             ',': 19846,\n",
              "             'm': 22243,\n",
              "             'k': 7088,\n",
              "             '.': 7885,\n",
              "             'A': 7819,\n",
              "             'l': 33339,\n",
              "             'S': 4523,\n",
              "             'Y': 1718,\n",
              "             'v': 7793,\n",
              "             '?': 2462,\n",
              "             'R': 4869,\n",
              "             'M': 2840,\n",
              "             'W': 3530,\n",
              "             \"'\": 6187,\n",
              "             'L': 3876,\n",
              "             'I': 11832,\n",
              "             'N': 5079,\n",
              "             'g': 13356,\n",
              "             ';': 3628,\n",
              "             'b': 11321,\n",
              "             '!': 2172,\n",
              "             'O': 5481,\n",
              "             'j': 628,\n",
              "             'V': 798,\n",
              "             '-': 1897,\n",
              "             'T': 7015,\n",
              "             'H': 3068,\n",
              "             'E': 6041,\n",
              "             'U': 3313,\n",
              "             'D': 2089,\n",
              "             'P': 1641,\n",
              "             'q': 609,\n",
              "             'x': 529,\n",
              "             'J': 320,\n",
              "             'G': 2399,\n",
              "             'K': 1584,\n",
              "             'Q': 231,\n",
              "             '&': 3,\n",
              "             'Z': 198,\n",
              "             'X': 112,\n",
              "             '3': 27,\n",
              "             '$': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "SAMPLE_SIZE = 500\n",
        "training_data_size = len(raw_training_data)\n",
        "start = random.randrange(0, training_data_size - SAMPLE_SIZE)\n",
        "print(raw_training_data[start:start+SAMPLE_SIZE])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Ly0EOSy-qolP",
        "outputId": "b3674d8e-01d4-4ae3-c6de-1bf2f5190964"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vel of the state was touch'd,\n",
            "They would not thread the gates. This kind of service\n",
            "Did not deserve corn gratis. Being i' the war\n",
            "Their mutinies and revolts, wherein they show'd\n",
            "Most valour, spoke not for them: the accusation\n",
            "Which they have often made against the senate,\n",
            "All cause unborn, could never be the motive\n",
            "Of our so frank donation. Well, what then?\n",
            "How shall this bisson multitude digest\n",
            "The senate's courtesy? Let deeds express\n",
            "What's like to be their words: 'we did request it;\n",
            "We are th\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = ''.join(sorted(set(raw_training_data)))\n",
        "token_to_number = {t: i for i, t in enumerate(tokens)}\n",
        "\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "c1mPJN2Pr97L",
        "outputId": "1854438b-95cc-4bfd-890e-c489fc00a78c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "number_to_token = {i: t for i, t in enumerate(tokens)}"
      ],
      "metadata": {
        "id": "YclkH_-gtE_k"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(s):\n",
        "  return_value = []\n",
        "  for character in s:\n",
        "    return_value.append(token_to_number[character])\n",
        "  return return_value\n",
        "\n",
        "encode(\"Tech Exchange\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sr-TVuUqtVAl",
        "outputId": "b7bd4d3b-6274-471d-f6f8-f189d601c175"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[32, 43, 41, 46, 1, 17, 62, 41, 46, 39, 52, 45, 43]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode(nums):\n",
        "  return ''.join([number_to_token[t_id] for t_id in nums])\n",
        "\n",
        "decode(encode(\"s\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "K3iXvsMquBKF",
        "outputId": "fff99de0-ffb6-4688-be32-280570546066"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'s'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "data = torch.tensor(encode(raw_training_data), dtype=torch.long)"
      ],
      "metadata": {
        "id": "XhrPBlIevXSX"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "holdout_size = int(0.1 * len(data))\n",
        "holdout_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2j99RUGzwS69",
        "outputId": "9637d2e0-c252-4fe5-e03c-99aa6762a3fa"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "111539"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = data[:holdout_size]\n",
        "training_data = data[holdout_size:]\n",
        "len(test_data), len(training_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLyAIYurwY2Y",
        "outputId": "6a611ebc-09c9-45e0-af4e-0d33f8f44a84"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(111539, 1003855)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BLOCK_SIZE = 8\n",
        "training_data[:BLOCK_SIZE+1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JodJqiAGxUfo",
        "outputId": "33d3262a-8159-46c4-bf5d-8b80e61d8d1d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([43, 58,  6,  1, 25, 39, 56, 41, 47])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_from = random.randint(0, training_data_size-BLOCK_SIZE)\n",
        "decode(training_data[start_from:start_from+BLOCK_SIZE].tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HIa25CdVx8P3",
        "outputId": "612b6dfd-3597-4ade-ab90-e780e799c603"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'and roya'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = training_data[:BLOCK_SIZE]\n",
        "y = training_data[1:BLOCK_SIZE+1]\n",
        "for t in range(BLOCK_SIZE):\n",
        "  context = x[:t+1]\n",
        "  target = y[t]\n",
        "  print(f\"in: {context}, out: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vVp_5-F3yuCf",
        "outputId": "25c77149-54fd-4972-852f-371313696a34"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "in: tensor([43]), out: 58\n",
            "in: tensor([43, 58]), out: 6\n",
            "in: tensor([43, 58,  6]), out: 1\n",
            "in: tensor([43, 58,  6,  1]), out: 25\n",
            "in: tensor([43, 58,  6,  1, 25]), out: 39\n",
            "in: tensor([43, 58,  6,  1, 25, 39]), out: 56\n",
            "in: tensor([43, 58,  6,  1, 25, 39, 56]), out: 41\n",
            "in: tensor([43, 58,  6,  1, 25, 39, 56, 41]), out: 47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)\n",
        "\n",
        "BATCH_SIZE = 4\n"
      ],
      "metadata": {
        "id": "Br-lT7980t04"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch(split):\n",
        "  data = training_data if split == 'train' else test_data\n",
        "  ix = torch.randint(len(data) - BLOCK_SIZE, (BATCH_SIZE,))\n",
        "  print(ix)\n",
        "  x = torch.stack([data[i:i+BLOCK_SIZE] for i in ix])\n",
        "  print(x)\n",
        "  y = torch.stack([data[i+1:i+BLOCK_SIZE+1] for i in ix])\n",
        "  print(y)\n",
        "  return x,y\n",
        "\n",
        "get_batch('train')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6OSOWC_l1EKK",
        "outputId": "d278105d-484d-45e2-b380-bccc1d8f612b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 74928, 231851, 934226, 560077])\n",
            "tensor([[42,  1, 58, 59, 56, 52, 57,  1],\n",
            "        [ 1, 17, 52, 45, 50, 39, 52, 42],\n",
            "        [47, 58, 46,  1, 46, 43, 56,  1],\n",
            "        [ 1, 46, 47, 57,  1, 44, 43, 50]])\n",
            "tensor([[ 1, 58, 59, 56, 52, 57,  1, 58],\n",
            "        [17, 52, 45, 50, 39, 52, 42,  5],\n",
            "        [58, 46,  1, 46, 43, 56,  1, 58],\n",
            "        [46, 47, 57,  1, 44, 43, 50, 50]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[42,  1, 58, 59, 56, 52, 57,  1],\n",
              "         [ 1, 17, 52, 45, 50, 39, 52, 42],\n",
              "         [47, 58, 46,  1, 46, 43, 56,  1],\n",
              "         [ 1, 46, 47, 57,  1, 44, 43, 50]]),\n",
              " tensor([[ 1, 58, 59, 56, 52, 57,  1, 58],\n",
              "         [17, 52, 45, 50, 39, 52, 42,  5],\n",
              "         [58, 46,  1, 46, 43, 56,  1, 58],\n",
              "         [46, 47, 57,  1, 44, 43, 50, 50]]))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xb, yb = get_batch('train')\n",
        "for b in range(BATCH_SIZE):\n",
        "  for t in range(BLOCK_SIZE):\n",
        "    context = xb[b, :t+1]\n",
        "    target = yb[b,t]\n",
        "    print(f'input {context.tolist()}, target {target}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eCjUsus3nM3",
        "outputId": "ac75c8fd-0e16-4584-ec76-60e64cbf7500"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([970212, 577172, 191660, 348195])\n",
            "tensor([[50, 47, 60, 43, 42,  1, 57, 53],\n",
            "        [45, 53, 53, 42,  1, 39,  1, 45],\n",
            "        [47, 45, 46, 58, 11,  0, 14, 59],\n",
            "        [52,  1, 58, 46, 63,  1, 44, 39]])\n",
            "tensor([[47, 60, 43, 42,  1, 57, 53,  1],\n",
            "        [53, 53, 42,  1, 39,  1, 45, 47],\n",
            "        [45, 46, 58, 11,  0, 14, 59, 58],\n",
            "        [ 1, 58, 46, 63,  1, 44, 39, 41]])\n",
            "input [50], target 47\n",
            "input [50, 47], target 60\n",
            "input [50, 47, 60], target 43\n",
            "input [50, 47, 60, 43], target 42\n",
            "input [50, 47, 60, 43, 42], target 1\n",
            "input [50, 47, 60, 43, 42, 1], target 57\n",
            "input [50, 47, 60, 43, 42, 1, 57], target 53\n",
            "input [50, 47, 60, 43, 42, 1, 57, 53], target 1\n",
            "input [45], target 53\n",
            "input [45, 53], target 53\n",
            "input [45, 53, 53], target 42\n",
            "input [45, 53, 53, 42], target 1\n",
            "input [45, 53, 53, 42, 1], target 39\n",
            "input [45, 53, 53, 42, 1, 39], target 1\n",
            "input [45, 53, 53, 42, 1, 39, 1], target 45\n",
            "input [45, 53, 53, 42, 1, 39, 1, 45], target 47\n",
            "input [47], target 45\n",
            "input [47, 45], target 46\n",
            "input [47, 45, 46], target 58\n",
            "input [47, 45, 46, 58], target 11\n",
            "input [47, 45, 46, 58, 11], target 0\n",
            "input [47, 45, 46, 58, 11, 0], target 14\n",
            "input [47, 45, 46, 58, 11, 0, 14], target 59\n",
            "input [47, 45, 46, 58, 11, 0, 14, 59], target 58\n",
            "input [52], target 1\n",
            "input [52, 1], target 58\n",
            "input [52, 1, 58], target 46\n",
            "input [52, 1, 58, 46], target 63\n",
            "input [52, 1, 58, 46, 63], target 1\n",
            "input [52, 1, 58, 46, 63, 1], target 44\n",
            "input [52, 1, 58, 46, 63, 1, 44], target 39\n",
            "input [52, 1, 58, 46, 63, 1, 44, 39], target 41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F"
      ],
      "metadata": {
        "id": "ZHYCHDcQ4dD9"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(set(raw_training_data))\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size):\n",
        "    super().__init__()\n",
        "    self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "  def forward(self, token, targets=None):\n",
        "    logits = self.token_embedding_table(token)\n",
        "\n",
        "    if targets is None:\n",
        "      loss = None\n",
        "    else:\n",
        "      B, T, C = logits.shape\n",
        "      logits = logits.view(B*T, C)\n",
        "      targets = targets.view(B*T)\n",
        "      loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "    return logits, loss\n",
        "\n",
        "  def generate(self, idx, max_new_tokens):\n",
        "    for _ in range(max_new_tokens):\n",
        "      logits, _ = self(idx)\n",
        "      logits = logits[:, -1, :] # (B, C)\n",
        "      probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "      idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "      idx = torch.cat((idx, idx_next), dim=1)\n",
        "    return idx\n",
        "\n",
        "m = BigramLanguageModel(vocab_size)\n",
        "z = torch.zeros((1,1), dtype=torch.long)\n",
        "print(decode(m.generate(z, 100)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIqMzWbN4kRG",
        "outputId": "587b3229-85a3-483d-fc07-fa89bebbe197"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LFyD\n",
            "NpKadPZrwBZ&PUa$WeRzgRDIL-UaKs,YwQC\n",
            ";G.VY3vHRnmuOKLPRH NNYG\n",
            "rh3rI3sfqz.yg$B-\n",
            "QmexOOxWERx&GYub!L\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "-np.log(1/65)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prghC_ssCkKm",
        "outputId": "fea52087-3648-410d-afbd-b9a17f42cd65"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.174387269895637"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MTiylQfOD2hs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}